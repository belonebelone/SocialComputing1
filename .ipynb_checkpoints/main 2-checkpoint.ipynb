{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d99075-b44c-45ed-9142-8d77eb65e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo le librerie\n",
    "import requests\n",
    "import pandas as pd\n",
    "from serpapi import GoogleScholarSearch\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "from pyvis.network import Network\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e127a3-fd0b-47ff-96cc-b286849b1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imposto Key\n",
    "GoogleScholarSearch.SERP_API_KEY = \"0026a7ce4493b9b56ff3f7d928218309e15fbd0e1d55db94bfae598695bb4540\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4f20b1-e1ec-4456-8f4d-946c4ea18c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. A partire da nodes.csv, utilizzare la libreria Python SerpAPI per scaricare, per ciascuno dei 7 autori elencati:\n",
    "# - author_id: ID identificativo del profilo Google Scholar\n",
    "# - cited_by: numero totale di citazioni ricevute\n",
    "# - interests: elenco degli interessi di ciascun autore\n",
    "# Sfruttando la libreria Python Pandas, usare la struttura dati DataFrame per\n",
    "# aggiornare il file originale con apposite colonne e memorizzarlo nella cartella /data.\n",
    "\n",
    "# Leggo file csv e carico dataframe\n",
    "df_nodes = pd.read_csv(\"data/nodes.csv\")\n",
    "# display(df_nodes)\n",
    "    \n",
    "# Creo dataframe ausiliario\n",
    "df_nodes_aux = pd.DataFrame(columns=[\"author_id\", \"cited_by\", \"interests\"])\n",
    "\n",
    "# Itero per la coppia name e affilations\n",
    "for name, affilations in zip(df_nodes[\"name\"], df_nodes[\"affiliations\"]):\n",
    "\n",
    "    # Ricerco name tra i profili presenti su Google Scholar\n",
    "    params = {\n",
    "        \"engine\": \"google_scholar_profiles\",\n",
    "        \"hl\": \"en\",\n",
    "        \"mauthors\": name\n",
    "    }\n",
    "\n",
    "    search = GoogleScholarSearch(params)\n",
    "    results = search.get_dict()[\"profiles\"]\n",
    "\n",
    "    # Tramite affilations so quale profilo scaricare\n",
    "    correct_affilations = None\n",
    "\n",
    "    for result in results:\n",
    "        if result[\"affiliations\"] == affilations:\n",
    "            correct_affilations = result\n",
    "\n",
    "    # display(\"correct_affilations: \", correct_affilations)\n",
    "\n",
    "    # -> Trovato profilo corretto !\n",
    "\n",
    "    # Creo DataFrame\n",
    "    author_id = correct_affilations.get('author_id')\n",
    "    cited_by = correct_affilations.get('cited_by', 'value')\n",
    "    interests = correct_affilations.get('interests')\n",
    "    title = None\n",
    "    for interest in interests: # interests dizionario -> estraggo title\n",
    "        title = interest.get('title', '')\n",
    "\n",
    "    # print(author_id)\n",
    "    # print(cited_by)\n",
    "    # print(title)\n",
    "\n",
    "    # non funziona append!\n",
    "    new_row = {'author_id': author_id, 'cited_by': cited_by, 'interests': title}\n",
    "    df_nodes_aux.loc[len(df_nodes_aux)] = new_row\n",
    "\n",
    "    # esco dal for\n",
    "\n",
    "# aggiorno il file originale con apposite colonne\n",
    "df = pd.concat([df_nodes, df_nodes_aux], axis=1)\n",
    "# display(df)\n",
    "\n",
    "# memorizzo dataframe\n",
    "df.to_csv(\"data/nodes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f48d5-2ef7-4966-8f94-cf975bc881c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Per ciascuno dei 7 autori, utilizzare il suo ID per accedere al relativo profilo Google\n",
    "#    Scholar e scaricare l’elenco dei suoi coautori, sempre via SerpAPI. Con tale elenco di nomi:\n",
    "# a. Utilizzare le SerpAPI per cercare su Google Scholar un ricercatore che corrisponde a tale nome. \n",
    "#    Per ciascuno, salvare name, affiliations, author_id, cited_by e interests in un nuovo DataFrame contenente tutte\n",
    "#    queste informazioni relative ai coautori dei 7 autori originari.\n",
    "# b. Concatenare il DataFrame con i 7 autori originari e quello dei coautori generato al punto 2a in un unico DataFrame.\n",
    "# NOTA BENE: è sufficiente effettuare la ricerca dei profili per nome, non accedere al loro profilo tramite id.\n",
    "# ASSUNZIONE: in questo caso non potete identificare il profilo corretto tramite il valore di affiliations, \n",
    "# quindi assumete che quello corretto sia il primo ritornato nella lista di authors.\n",
    "# c. Creare un terzo DataFrame con le colonne author1, author2 che rappresenta le co-authorship. \n",
    "# In tale DataFrame, una riga rappresenta un arco di coauthorship tra due autori.\n",
    "\n",
    "# Leggo file csv e carico dataframe\n",
    "df_nodes = pd.read_csv(\"data/nodes.csv\")\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# Creo dataframe ausiliario per i coautori\n",
    "#df_coauthor = pd.DataFrame(\n",
    "#    columns=[\"coauthor_name\", \"coauthor_affiliations\", \"coauthor_author_id\", \"coauthor_cited_by\",\n",
    "#             \"coauthor_interests\"])\n",
    "df_coauthor = pd.DataFrame(columns=[\"name\", \"affiliations\", \"author_id\", \"cited_by\", \"interests\"])\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "df_edges = pd.DataFrame(columns=[\"author1\", \"author2\"])\n",
    "                            \n",
    "for name, author_id in zip(df_nodes[\"name\"], df_nodes[\"author_id\"]):\n",
    "        \n",
    "    # print(author_id)\n",
    "        \n",
    "    params = {\n",
    "        \"engine\": \"google_scholar_author\",\n",
    "        \"hl\": \"en\",\n",
    "        \"author_id\": author_id\n",
    "    }\n",
    "\n",
    "    search = GoogleScholarSearch(params)\n",
    "    results_author_id = search.get_dict()  # elenco di coautori per ciascun autore\n",
    "\n",
    "    # a. Utilizzare le SerpAPI per cercare su Google Scholar un ricercatore che\n",
    "    # corrisponde a tale nome. Per ciascuno, salvare name, affiliations,\n",
    "    # author_id, cited_by e interests in un nuovo DataFrame contenente tutte\n",
    "    # queste informazioni relative ai coautori dei 7 autori originari.\n",
    "\n",
    "    for coauthor in results_author_id[\"co_authors\"]:\n",
    "\n",
    "        coauthor_name = {coauthor['name']}\n",
    "\n",
    "        # trova ricercatore che corrisponde a tale nome\n",
    "\n",
    "        # Ricerco name tra i profili presenti su Google Scholar\n",
    "        params = {\n",
    "            \"engine\": \"google_scholar_profiles\",\n",
    "            \"hl\": \"en\",\n",
    "            \"mauthors\": coauthor_name\n",
    "        }\n",
    "\n",
    "        search = GoogleScholarSearch(params)\n",
    "\n",
    "        # prendo primo profilo\n",
    "        results_author_id_profile = search.get_dict()[\"profiles\"][0]\n",
    "        results_author_id_profile1 = results_author_id_profile\n",
    "        # print(results_author_id_profile1)\n",
    "            \n",
    "        # Per ciascuno, salvare name, affiliations, author_id, cited_by e interests\n",
    "        # in un nuovo DataFrame contenente tutte queste informazioni relative ai coautori\n",
    "        # dei 7 autori originari.\n",
    "              \n",
    "        # Creo variabili:\n",
    "        coauthor_affiliations = results_author_id_profile1.get('affiliations')\n",
    "        # print(coauthor_affilations)\n",
    "        coauthor_id = results_author_id_profile1.get('author_id')\n",
    "        # print(coauthor_id)\n",
    "        coauthor_cited_by = results_author_id_profile1.get('cited_by', 'value')\n",
    "        # print(coauthor_cited_by)\n",
    "        coauthor_interests = results_author_id_profile1.get('interests')\n",
    "        # print(coauthor_interests)\n",
    "        coauthor_title = None\n",
    "\n",
    "        # title può essere None -> se vero lo imposto null\n",
    "        try: \n",
    "            for interest in coauthor_interests:\n",
    "                coauthor_title = interest.get('title', '')\n",
    "        except:\n",
    "            coauthor_title = \"\"\n",
    "\n",
    "        # non funziona append!\n",
    "        # creo riga da aggiungere a df_coauthor\n",
    "        new_row_coauthor = {'name': coauthor_name, 'affiliations': coauthor_affiliations, 'author_id': coauthor_id, 'cited_by': coauthor_cited_by, 'interests': coauthor_title}\n",
    "        \n",
    "        # aggiungo riga a df_coauthor\n",
    "        df_coauthor.loc[len(df_coauthor)] = new_row_coauthor\n",
    "\n",
    "        #name, coauthor_name\n",
    "            \n",
    "        new_row_edges = {'author1': name, 'author2': coauthor_name}\n",
    "            \n",
    "        df_edges.loc[len(df_edges)] = new_row_edges\n",
    "\n",
    "            \n",
    "        #print(new_row)\n",
    "            \n",
    "        # esco dal secondo for\n",
    "    # esco dal primo for\n",
    "    \n",
    "display(df_coauthor)\n",
    "    \n",
    "# b. Concatenare il DataFrame con i 7 autori originari e quello dei coautori\n",
    "# generato al punto 2a in un unico DataFrame.\n",
    "# NOTA BENE: è sufficiente effettuare la ricerca dei profili per nome, non\n",
    "# accedere al loro profilo tramite id.\n",
    "# ASSUNZIONE: in questo caso non potete identificare il profilo corretto tramite\n",
    "# il valore di affiliations, quindi assumete che quello corretto sia il primo\n",
    "# ritornato nella lista di authors.\n",
    "\n",
    "# salvataggio non neccessario -> eseguito solo per velocizzare il programma\n",
    "df_coauthor.to_csv(\"data/coauthor.csv\", index=False)\n",
    "\n",
    "# concateno il DataFrame con i 7 autori originari e quello dei coautori\n",
    "df_nodes = pd.concat([df_nodes, df_coauthor], ignore_index=True)\n",
    "\n",
    "# c. Creare un terzo DataFrame con le colonne author1, author2 che\n",
    "# rappresenta le co-authorship. In tale DataFrame, una riga rappresenta un\n",
    "# arco di coauthorship tra due autori.\n",
    "# ESEMPIO: David La Barbera, Michael Soprano è una riga del DataFrame\n",
    "# creato al punto 2c se Michael Soprano è coautore di David La Barbera. La\n",
    "# co-authorship è binaria, non pesata.\n",
    "\n",
    "    \n",
    "# df_edges = pd.DataFrame(columns=[\"author1\", \"author2\"])\n",
    "\n",
    "# df_edges = pd.concat([df_nodes[\"name\"], df_coauthor[\"coauthor_name\"]], axis=1)\n",
    "\n",
    "df_edges.to_csv(\"data/edges.csv\", index=False)\n",
    "\n",
    "# A questo punto avrete prodotto due DataFrame:\n",
    "# - Uno per le informazioni relative agli autori (originali + i relativi coautori) e \n",
    "#   contenente per ciascuno di essi i valori di name, affiliations, cited_by, interests. \n",
    "#   Salvare come nodes.csv nella cartella /data tale DataFrame.\n",
    "# - Uno per le relazioni di co-authorship dai 7 autori principali verso i relativi coautori con colonne author1, author2. \n",
    "#   Salvare come edges.csv nella cartella /data tale DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619276f4-454e-4f29-846f-b051fd3cbb27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f49f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75853c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
