{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d99075-b44c-45ed-9142-8d77eb65e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo le librerie\n",
    "import requests\n",
    "import pandas as pd\n",
    "from serpapi import GoogleScholarSearch\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "from pyvis.network import Network\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08e127a3-fd0b-47ff-96cc-b286849b1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imposto Key\n",
    "GoogleScholarSearch.SERP_API_KEY = \"5137659bcfa1c48c5ef9cb22d32468b7c6f58739e298365157e18a98ecdbb832\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4f20b1-e1ec-4456-8f4d-946c4ea18c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. A partire da nodes.csv, utilizzare la libreria Python SerpAPI per scaricare, per ciascuno dei 7 autori elencati:\n",
    "# - author_id: ID identificativo del profilo Google Scholar\n",
    "# - cited_by: numero totale di citazioni ricevute\n",
    "# - interests: elenco degli interessi di ciascun autore\n",
    "# Sfruttando la libreria Python Pandas, usare la struttura dati DataFrame per\n",
    "# aggiornare il file originale con apposite colonne e memorizzarlo nella cartella /data.\n",
    "\n",
    "# Leggo file csv e carico dataframe\n",
    "df_nodes = pd.read_csv(\"data/nodes.csv\")\n",
    "# display(df_nodes)\n",
    "    \n",
    "# Creo dataframe ausiliario\n",
    "df_nodes_aux = pd.DataFrame(columns=[\"author_id\", \"cited_by\", \"interests\"])\n",
    "\n",
    "# Itero per la coppia name e affilations\n",
    "for name, affilations in zip(df_nodes[\"name\"], df_nodes[\"affiliations\"]):\n",
    "\n",
    "    # Ricerco name tra i profili presenti su Google Scholar\n",
    "    params = {\n",
    "        \"engine\": \"google_scholar_profiles\",\n",
    "        \"hl\": \"en\",\n",
    "        \"mauthors\": name\n",
    "    }\n",
    "\n",
    "    search = GoogleScholarSearch(params)\n",
    "    results = search.get_dict()[\"profiles\"]\n",
    "\n",
    "    # Tramite affilations so quale profilo scaricare\n",
    "    correct_affilations = None\n",
    "\n",
    "    for result in results:\n",
    "        if result[\"affiliations\"] == affilations:\n",
    "            correct_affilations = result\n",
    "\n",
    "    # display(\"correct_affilations: \", correct_affilations)\n",
    "\n",
    "    # -> Trovato profilo corretto !\n",
    "\n",
    "    # Creo DataFrame\n",
    "    author_id = correct_affilations.get('author_id')\n",
    "    cited_by = correct_affilations.get('cited_by', 'value')\n",
    "    interests = correct_affilations.get('interests')\n",
    "    title = None\n",
    "    for interest in interests: # interests dizionario -> estraggo title\n",
    "        title = interest.get('title', '')\n",
    "\n",
    "    # print(author_id)\n",
    "    # print(cited_by)\n",
    "    # print(title)\n",
    "\n",
    "    # non funziona append!\n",
    "    new_row = {'author_id': author_id, 'cited_by': cited_by, 'interests': title}\n",
    "    df_nodes_aux.loc[len(df_nodes_aux)] = new_row\n",
    "\n",
    "    # esco dal for\n",
    "\n",
    "# aggiorno il file originale con apposite colonne\n",
    "df = pd.concat([df_nodes, df_nodes_aux], axis=1)\n",
    "# display(df)\n",
    "\n",
    "# memorizzo dataframe\n",
    "df.to_csv(\"data/nodes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b3f48d5-2ef7-4966-8f94-cf975bc881c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>affiliations</th>\n",
       "      <th>author_id</th>\n",
       "      <th>cited_by</th>\n",
       "      <th>interests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kevin Roitero</td>\n",
       "      <td>University of Udine</td>\n",
       "      <td>1xd52jMAAAAJ</td>\n",
       "      <td>690</td>\n",
       "      <td>Information Retrieval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stefano Mizzaro</td>\n",
       "      <td>Full professor of Computer Science and Informa...</td>\n",
       "      <td>2wvJC6IAAAAJ</td>\n",
       "      <td>4739</td>\n",
       "      <td>misinformation and fake news detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gianluca Demartini</td>\n",
       "      <td>Associate Professor at the University of Queen...</td>\n",
       "      <td>PCAiILsAAAAJ</td>\n",
       "      <td>5348</td>\n",
       "      <td>Crowdsourcing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Damiano Spina</td>\n",
       "      <td>School of Computing Technologies, RMIT University</td>\n",
       "      <td>sLzYrNYAAAAJ</td>\n",
       "      <td>2483</td>\n",
       "      <td>Human-AI Fact-checking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Soprano</td>\n",
       "      <td>Postdoctoral Research Fellow at the University...</td>\n",
       "      <td>ocK0qRUAAAAJ</td>\n",
       "      <td>210</td>\n",
       "      <td>Crowdsourcing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Pavlos Vougiouklis</td>\n",
       "      <td>Huawei Technologies</td>\n",
       "      <td>9J7YeR0AAAAJ</td>\n",
       "      <td>576</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Jonathon Hare</td>\n",
       "      <td>NOAA Fisheries, Northeast Fisheries Science Ce...</td>\n",
       "      <td>d_HvmVsAAAAJ</td>\n",
       "      <td>12279</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Carlo Alberto Beltrami</td>\n",
       "      <td>Professore, Università di Udine</td>\n",
       "      <td>EZrMWWMAAAAJ</td>\n",
       "      <td>18388</td>\n",
       "      <td>cellule staminali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Richard Gomer</td>\n",
       "      <td>Professor of Biology, Texas A&amp;M University</td>\n",
       "      <td>z1YBrC4AAAAJ</td>\n",
       "      <td>10316</td>\n",
       "      <td>cell density sensing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Davide Ceolin</td>\n",
       "      <td>Tenured Researcher, CWI Amsterdam</td>\n",
       "      <td>y8Jy518AAAAJ</td>\n",
       "      <td>497</td>\n",
       "      <td>Provenance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  \\\n",
       "0             Kevin Roitero   \n",
       "1           Stefano Mizzaro   \n",
       "2        Gianluca Demartini   \n",
       "3             Damiano Spina   \n",
       "4           Michael Soprano   \n",
       "..                      ...   \n",
       "122      Pavlos Vougiouklis   \n",
       "123           Jonathon Hare   \n",
       "124  Carlo Alberto Beltrami   \n",
       "125           Richard Gomer   \n",
       "126           Davide Ceolin   \n",
       "\n",
       "                                          affiliations     author_id  \\\n",
       "0                                  University of Udine  1xd52jMAAAAJ   \n",
       "1    Full professor of Computer Science and Informa...  2wvJC6IAAAAJ   \n",
       "2    Associate Professor at the University of Queen...  PCAiILsAAAAJ   \n",
       "3    School of Computing Technologies, RMIT University  sLzYrNYAAAAJ   \n",
       "4    Postdoctoral Research Fellow at the University...  ocK0qRUAAAAJ   \n",
       "..                                                 ...           ...   \n",
       "122                                Huawei Technologies  9J7YeR0AAAAJ   \n",
       "123  NOAA Fisheries, Northeast Fisheries Science Ce...  d_HvmVsAAAAJ   \n",
       "124                    Professore, Università di Udine  EZrMWWMAAAAJ   \n",
       "125         Professor of Biology, Texas A&M University  z1YBrC4AAAAJ   \n",
       "126                  Tenured Researcher, CWI Amsterdam  y8Jy518AAAAJ   \n",
       "\n",
       "     cited_by                               interests  \n",
       "0         690                   Information Retrieval  \n",
       "1        4739  misinformation and fake news detection  \n",
       "2        5348                           Crowdsourcing  \n",
       "3        2483                  Human-AI Fact-checking  \n",
       "4         210                           Crowdsourcing  \n",
       "..        ...                                     ...  \n",
       "122       576                                          \n",
       "123     12279                              management  \n",
       "124     18388                       cellule staminali  \n",
       "125     10316                    cell density sensing  \n",
       "126       497                              Provenance  \n",
       "\n",
       "[127 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Per ciascuno dei 7 autori, utilizzare il suo ID per accedere al relativo profilo Google\n",
    "#    Scholar e scaricare l’elenco dei suoi coautori, sempre via SerpAPI. Con tale elenco di nomi:\n",
    "# a. Utilizzare le SerpAPI per cercare su Google Scholar un ricercatore che corrisponde a tale nome. \n",
    "#    Per ciascuno, salvare name, affiliations, author_id, cited_by e interests in un nuovo DataFrame contenente tutte\n",
    "#    queste informazioni relative ai coautori dei 7 autori originari.\n",
    "# b. Concatenare il DataFrame con i 7 autori originari e quello dei coautori generato al punto 2a in un unico DataFrame.\n",
    "# NOTA BENE: è sufficiente effettuare la ricerca dei profili per nome, non accedere al loro profilo tramite id.\n",
    "# ASSUNZIONE: in questo caso non potete identificare il profilo corretto tramite il valore di affiliations, \n",
    "# quindi assumete che quello corretto sia il primo ritornato nella lista di authors.\n",
    "# c. Creare un terzo DataFrame con le colonne author1, author2 che rappresenta le co-authorship. \n",
    "# In tale DataFrame, una riga rappresenta un arco di coauthorship tra due autori.\n",
    "\n",
    "# Leggo file csv e carico dataframe\n",
    "df_nodes = pd.read_csv(\"data/nodes.csv\")\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# Creo dataframe ausiliario per i coautori\n",
    "#df_coauthor = pd.DataFrame(\n",
    "#    columns=[\"coauthor_name\", \"coauthor_affiliations\", \"coauthor_author_id\", \"coauthor_cited_by\",\n",
    "#             \"coauthor_interests\"])\n",
    "df_coauthor = pd.DataFrame(columns=[\"name\", \"affiliations\", \"author_id\", \"cited_by\", \"interests\"])\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "df_edges = pd.DataFrame(columns=[\"author1\", \"author2\"])\n",
    "                            \n",
    "for name, author_id in zip(df_nodes[\"name\"], df_nodes[\"author_id\"]):\n",
    "        \n",
    "    # print(author_id)\n",
    "        \n",
    "    params = {\n",
    "        \"engine\": \"google_scholar_author\",\n",
    "        \"hl\": \"en\",\n",
    "        \"author_id\": author_id\n",
    "    }\n",
    "\n",
    "    search = GoogleScholarSearch(params)\n",
    "    results_author_id = search.get_dict()  # elenco di coautori per ciascun autore\n",
    "\n",
    "    # a. Utilizzare le SerpAPI per cercare su Google Scholar un ricercatore che\n",
    "    # corrisponde a tale nome. Per ciascuno, salvare name, affiliations,\n",
    "    # author_id, cited_by e interests in un nuovo DataFrame contenente tutte\n",
    "    # queste informazioni relative ai coautori dei 7 autori originari.\n",
    "\n",
    "    for coauthor in results_author_id[\"co_authors\"]:\n",
    "\n",
    "        coauthor_name = coauthor['name']\n",
    "\n",
    "        # trova ricercatore che corrisponde a tale nome\n",
    "\n",
    "        # Ricerco name tra i profili presenti su Google Scholar\n",
    "        params = {\n",
    "            \"engine\": \"google_scholar_profiles\",\n",
    "            \"hl\": \"en\",\n",
    "            \"mauthors\": coauthor_name\n",
    "        }\n",
    "\n",
    "        search = GoogleScholarSearch(params)\n",
    "\n",
    "        # prendo primo profilo\n",
    "        results_author_id_profile = search.get_dict()[\"profiles\"][0]\n",
    "        results_author_id_profile1 = results_author_id_profile\n",
    "        # print(results_author_id_profile1)\n",
    "            \n",
    "        # Per ciascuno, salvare name, affiliations, author_id, cited_by e interests\n",
    "        # in un nuovo DataFrame contenente tutte queste informazioni relative ai coautori\n",
    "        # dei 7 autori originari.\n",
    "              \n",
    "        # Creo variabili:\n",
    "        coauthor_affiliations = results_author_id_profile1.get('affiliations')\n",
    "        # print(coauthor_affilations)\n",
    "        coauthor_id = results_author_id_profile1.get('author_id')\n",
    "        # print(coauthor_id)\n",
    "        coauthor_cited_by = results_author_id_profile1.get('cited_by', 'value')\n",
    "        # print(coauthor_cited_by)\n",
    "        coauthor_interests = results_author_id_profile1.get('interests')\n",
    "        # print(coauthor_interests)\n",
    "        coauthor_title = None\n",
    "\n",
    "        # title può essere None -> se vero lo imposto null\n",
    "        try: \n",
    "            for interest in coauthor_interests:\n",
    "                coauthor_title = interest.get('title', '')\n",
    "        except:\n",
    "            coauthor_title = \"\"\n",
    "\n",
    "        # non funziona append!\n",
    "        # creo riga da aggiungere a df_coauthor\n",
    "        new_row_coauthor = {'name': coauthor_name, 'affiliations': coauthor_affiliations, 'author_id': coauthor_id, 'cited_by': coauthor_cited_by, 'interests': coauthor_title}\n",
    "        \n",
    "        # aggiungo riga a df_coauthor\n",
    "        df_coauthor.loc[len(df_coauthor)] = new_row_coauthor\n",
    "\n",
    "        #name, coauthor_name\n",
    "            \n",
    "        new_row_edges = {'author1': name, 'author2': coauthor_name}\n",
    "            \n",
    "        df_edges.loc[len(df_edges)] = new_row_edges\n",
    "\n",
    "            \n",
    "        #print(new_row)\n",
    "            \n",
    "        # esco dal secondo for\n",
    "    # esco dal primo for\n",
    "    \n",
    "display(df_coauthor)\n",
    "    \n",
    "# b. Concatenare il DataFrame con i 7 autori originari e quello dei coautori\n",
    "# generato al punto 2a in un unico DataFrame.\n",
    "# NOTA BENE: è sufficiente effettuare la ricerca dei profili per nome, non\n",
    "# accedere al loro profilo tramite id.\n",
    "# ASSUNZIONE: in questo caso non potete identificare il profilo corretto tramite\n",
    "# il valore di affiliations, quindi assumete che quello corretto sia il primo\n",
    "# ritornato nella lista di authors.\n",
    "\n",
    "# salvataggio non neccessario -> eseguito solo per velocizzare il programma\n",
    "df_coauthor.to_csv(\"data/coauthor.csv\", index=False)\n",
    "\n",
    "# concateno il DataFrame con i 7 autori originari e quello dei coautori\n",
    "df_nodes = pd.concat([df_nodes, df_coauthor], ignore_index=True)\n",
    "\n",
    "# c. Creare un terzo DataFrame con le colonne author1, author2 che\n",
    "# rappresenta le co-authorship. In tale DataFrame, una riga rappresenta un\n",
    "# arco di coauthorship tra due autori.\n",
    "# ESEMPIO: David La Barbera, Michael Soprano è una riga del DataFrame\n",
    "# creato al punto 2c se Michael Soprano è coautore di David La Barbera. La\n",
    "# co-authorship è binaria, non pesata.\n",
    "\n",
    "    \n",
    "# df_edges = pd.DataFrame(columns=[\"author1\", \"author2\"])\n",
    "\n",
    "# df_edges = pd.concat([df_nodes[\"name\"], df_coauthor[\"coauthor_name\"]], axis=1)\n",
    "\n",
    "df_edges.to_csv(\"data/edges.csv\", index=False)\n",
    "\n",
    "# A questo punto avrete prodotto due DataFrame:\n",
    "# - Uno per le informazioni relative agli autori (originali + i relativi coautori) e \n",
    "#   contenente per ciascuno di essi i valori di name, affiliations, cited_by, interests. \n",
    "#   Salvare come nodes.csv nella cartella /data tale DataFrame.\n",
    "# - Uno per le relazioni di co-authorship dai 7 autori principali verso i relativi coautori con colonne author1, author2. \n",
    "#   Salvare come edges.csv nella cartella /data tale DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619276f4-454e-4f29-846f-b051fd3cbb27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f49f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75853c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
